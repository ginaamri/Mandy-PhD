"phb_vorsichgeht",
"phb_raum",
"phb_gestik",
"phb_alleangesehen",
"ps_deutlich",
"ps_klar",
"ps_impulse",
"pi_nonverbal",
"pi_zubewegen",
"pi_direkt",
"m_natürlich",
"m_fiktiv",
"m_verhalten"),
collapse = '|')))
# value sometimes contained text before filtering, we have to convert the numbers to numeric
quest.raw.data <- quest.raw.data %>%  mutate(value = as.numeric(value))
# create a basic table (tibble) using tidyverse functions
scale.quest.table <- quest.raw.data %>% # select data
group_by(scale) %>%
summarise("M scale" = round(mean(value), 2),
"SD scale" = round(sd(value), 2),
"min scale" = min(value),
"max sclae" = max(value))
# remove duplicate labels from the table column "group" to create the APA-style omission of categorical variables
# this is easier than the stub_indent option in apa_table
scale.quest.table$group[duplicated(scale.quest.table$group)] <- ""
### classroom management
# filter by parameter variable, i.e. create a subset for classroom management
cm.data <- quest.raw.data %>% filter(scale == "Classroom management")
# value sometimes contained text before filtering, we have to convert the numbers to numeric
cm.data <- cm.data %>%  mutate(value = as.numeric(as.character(factor(value))))
# to create error bars, we need to summarize the data in a separate data frame
cm.plot.sd <- cm.data %>%
group_by(group, item.wordings, .drop=TRUE) %>%
summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )
# long plot
cm.plot<-ggplot(data = cm.plot.sd,
aes(x = item.wordings, y = mean,
group = group, colour = group)) +
geom_line()+
geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
theme_light() +
ylim(1,4)+
facet_grid(~perspective)+
labs(data = cm.data, y = "value", x = NULL,
title="Classroom management" ,
subtitle=NULL)+
theme(legend.position="bottom",
panel.spacing.x = ,
plot.title = element_text(hjust = 0.5),
axis.text.y = element_text(size = 6))+
scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
coord_flip()
cm.plot
### Positive climate and motivation
# filter by parameter variable, i.e. create a subset for Positive climate and motivation
pcm.data <- quest.raw.data %>% filter(scale == "Positive climate and motivation")
# value sometimes contained text before filtering, we have to convert the numbers to numeric
pcm.data <- pcm.data %>%  mutate(value = as.numeric(as.character(factor(value))))
# to create error bars, we need to summarize the data in a separate data frame
pcm.plot.sd <- pcm.data %>%
group_by(group, item.wordings, .drop=TRUE) %>%
summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )
# long plot
pcm.plot<-ggplot(data = pcm.plot.sd,
aes(x = item.wordings, y = mean,
group = group, colour = group)) +
geom_line()+
geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
theme_light() +
ylim(1,4)+
facet_grid(~perspective)+
labs(data = pcm.data, y = "value", x = NULL,
title="Positive climate and motivation" ,
subtitle=NULL)+
theme(legend.position="bottom",
panel.spacing.x = ,
plot.title = element_text(hjust = 0.5),
axis.text.y = element_text(size = 5))+
scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
coord_flip()
pcm.plot
### Clarity and structuredness
# filter by parameter variable, i.e. create a subset for Clarity and structuredness
cs.data <- quest.raw.data %>% filter(scale == "Clarity and structuredness")
# value sometimes contained text before filtering, we have to convert the numbers to numeric
cs.data <- cs.data %>%  mutate(value = as.numeric(as.character(factor(value))))
# to create error bars, we need to summarize the data in a separate data frame
cs.plot.sd <- cs.data %>%
group_by(group, item.wordings, .drop=TRUE) %>%
summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )
# long plot
cs.plot<-ggplot(data = cs.plot.sd,
aes(x = item.wordings, y = mean,
group = group, colour = group)) +
geom_line()+
geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
theme_light() +
ylim(1,4)+
facet_grid(~perspective)+
labs(data = cs.data, y = "value", x = NULL,
title="Clarity and structuredness" ,
subtitle=NULL)+
theme(legend.position="bottom",
panel.spacing.x = ,
plot.title = element_text(hjust = 0.5),
axis.text.y = element_text(size = 6))+
scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
coord_flip()
cs.plot
### Activation and support
# filter by parameter variable, i.e. create a subset for Activation and support
as.data <- quest.raw.data %>% filter(scale == "Activation and support")
# value sometimes contained text before filtering, we have to convert the numbers to numeric
as.data <- as.data %>%  mutate(value = as.numeric(as.character(factor(value))))
# to create error bars, we need to summarize the data in a separate data frame
as.plot.sd <- as.data %>%
group_by(group, item.wordings, .drop=TRUE) %>%
summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )
# long plot
as.plot<-ggplot(data = as.plot.sd,
aes(x = item.wordings, y = mean,
group = group, colour = group)) +
geom_line()+
geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
theme_light() +
ylim(1,4)+
facet_grid(~perspective)+
labs(data = as.data, y = "value", x = NULL,
title="Activation and support" ,
subtitle=NULL)+
theme(legend.position="bottom",
panel.spacing.x = ,
plot.title = element_text(hjust = 0.5),
axis.text.y = element_text(size = 6))+
scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
coord_flip()
as.plot
knitr::include_graphics("./pictures/presenceposturegaze.png", dpi = 108)
# ```{r Presence: posture/gaze line plots,  fig.width=6, fig.height = 6, message = FALSE, warning = FALSE , echo=FALSE}
# ### Presence: posture/gaze
#
# # filter by parameter variable, i.e. create a subset for Presence: posture/gaze
# ppg.data <- quest.raw.data %>% filter(scale == "Presence: posture/gaze")
#
# # value sometimes contained text before filtering, we have to convert the numbers to numeric
# ppg.data <- ppg.data %>%  mutate(value = as.numeric(as.character(factor(value))))
#
# # to create error bars, we need to summarize the data in a separate data frame
# ppg.plot.sd <- ppg.data %>%
#   group_by(group, item.wordings, .drop=TRUE) %>%
#   summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )
#
# # long plot
# ppg.plot<-ggplot(data = ppg.plot.sd,
#                   aes(x = item.wordings, y = mean,
#                       group = group, colour = group)) +
#   geom_line()+
#   geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
#   theme_light() +
#   ylim(1,4)+
#   facet_grid(~perspective)+
#   labs(data = ppg.data, y = "value", x = NULL,
#        title="Presence: posture/gaze" ,
#        subtitle=NULL)+
#   theme(legend.position="bottom",
#         panel.spacing.x = ,
#         plot.title = element_text(hjust = 0.5),
#         axis.text.y = element_text(size = 6))+
#   scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
#   coord_flip()
# ppg.plot
knitr::include_graphics("./pictures/presencevoice.png", dpi = 108)
# ```{r Presence: voice line plots,  fig.width=6, fig.height = 6, message = FALSE, warning = FALSE , echo=FALSE}
#
# ### Presence: voice
# # filter by parameter variable, i.e. create a subset for Presence: voice
# pv.data <- quest.raw.data %>% filter(scale == "Presence: voice")
#
# # value sometimes contained text before filtering, we have to convert the numbers to numeric
# pv.data <- pv.data %>%  mutate(value = as.numeric(as.character(factor(value))))
#
# # to create error bars, we need to summarize the data in a separate data frame
# pv.plot.sd <- pv.data %>%
#   group_by(group, item.wordings, .drop=TRUE) %>%
#   summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )
#
# # long plot
# pv.plot<-ggplot(data = pv.plot.sd,
#                   aes(x = item.wordings, y = mean,
#                       group = group, colour = group)) +
#   geom_line()+
#   geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
#   theme_light() +
#   ylim(1,4)+
#   facet_grid(~perspective)+
#   labs(data = pv.data, y = "value", x = NULL,
#        title="Presence: voice" ,
#        subtitle=NULL)+
#   theme(legend.position="bottom",
#         panel.spacing.x = ,
#         plot.title = element_text(hjust = 0.5),
#         axis.text.y = element_text(size = 6))+
#   scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
#   coord_flip()
# pv.plot
knitr::include_graphics("./pictures/presenceverbalnonverbalintervention.png", dpi = 108)
# ```{r Presence: verbal and non-verbal intervention line plots,  fig.width=6, fig.height = 6, message = FALSE, warning = FALSE , echo=FALSE}
#
# ### Presence: verbal and non-verbal intervention
# # filter by parameter variable, i.e. create a subset for Presence: verbal and non-verbal intervention
# pvni.data <- quest.raw.data %>% filter(scale == "Presence: verbal and non-verbal intervention")
#
# # value sometimes contained text before filtering, we have to convert the numbers to numeric
# pvni.data <- pvni.data %>%  mutate(value = as.numeric(as.character(factor(value))))
#
# # to create error bars, we need to summarize the data in a separate data frame
# pvni.plot.sd <- pvni.data %>%
#   group_by(group, item.wordings, .drop=TRUE) %>%
#   summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )
#
# # long plot
# pvni.plot<-ggplot(data = pvni.plot.sd,
#                   aes(x = item.wordings, y = mean,
#                       group = group, colour = group)) +
#   geom_line()+
#   geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
#   theme_light() +
#   ylim(1,4)+
#   facet_grid(~perspective)+
#   labs(data = pvni.data, y = "value", x = NULL,
#        title="Presence: verbal and non-verbal intervention" ,
#        subtitle=NULL)+
#   theme(legend.position="bottom",
#         panel.spacing.x = ,
#         plot.title = element_text(hjust = 0.5),
#         axis.text.y = element_text(size = 6))+
#   scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
#   coord_flip()
# pvni.plot
### Natural behaviour
# filter by parameter variable, i.e. create a subset for Natural behaviour
nb.data <- quest.raw.data %>% filter(scale == "Natural behaviour")
# value sometimes contained text before filtering, we have to convert the numbers to numeric
nb.data <- nb.data %>%  mutate(value = as.numeric(as.character(factor(value))))
# to create error bars, we need to summarize the data in a separate data frame
nb.plot.sd <- nb.data %>%
group_by(group, item.wordings, .drop=TRUE) %>%
summarise(perspective, mean = mean(value), n = n(), sd = sd(value), se = sd/sqrt(n), )
# long plot
nb.plot<-ggplot(data = nb.plot.sd,
aes(x = item.wordings, y = mean,
group = group, colour = group)) +
geom_line()+
geom_pointrange(position = position_dodge(0.1), aes(ymin = mean-se, ymax = mean+se))+
theme_light() +
ylim(1,4)+
facet_grid(~perspective)+
labs(data = nb.data, y = "value", x = NULL,
title="Natural behaviour" ,
subtitle=NULL)+
theme(legend.position="bottom",
panel.spacing.x = ,
plot.title = element_text(hjust = 0.5),
axis.text.y = element_text(size = 6))+
scale_x_discrete(labels = function(x) str_wrap(x, width = 55))+
coord_flip()
nb.plot
quest.plot <- quest.raw.data %>%
ggplot(aes(x=scale, y=value, fill=scale)) +
geom_boxplot() +
scale_x_discrete(guide = guide_axis(angle = 70)) +
geom_jitter(color="black", size=0.4, alpha=0.9) +
theme_light() +
theme(
legend.position="none",
plot.title = element_text(size=11)
) +
facet_grid(~group)+
ggtitle("Boxplot with individual points for all scales") +
xlab("")
quest.plot
### read in data for 01_01_expert_D
speaking.data.01.01 <- read.delim("./data/Aperol_pilot_01_01_expert_D_cam4_AL_MK.txt", dec=",", sep="\t", header=T)
### select relevant columns
speaking.data.01.01 <- speaking.data.01.01  %>% select(
Dokumentgruppe,
Dokumentname,
Code,
Anfang,
Ende,
Fläche,
Abdeckungsgrad..)
### filter only speaking time of teacher and "kodiert von Anna" as row
speaking.data.01.01 <- speaking.data.01.01 %>% filter (Code == "speaking time\\teacher",
Dokumentgruppe == "kodiert von Anna")
speaking.data.01.01 <- sum(speaking.data.01.01$Abdeckungsgrad..)
# read in data for 01_02_expert_A
speaking.data.01.02 <- read.delim("./data/Aperol_pilot_01_02_expert_A_cam1_AL.txt", dec=",", sep="\t", header=T)
### select relevant columns
speaking.data.01.02 <- speaking.data.01.02 %>% select(
Dokumentname,
Code,
Anfang,
Ende,
Fläche,
Abdeckungsgrad..)
### filter only speaking time of teacher as row
speaking.data.01.02 <- speaking.data.01.02 %>% filter (Code == "speaking time\\teacher")
speaking.data.01.02 <- sum(speaking.data.01.02$Abdeckungsgrad..)
# read in data for 01_03_novice_B
speaking.data.01.03 <- read.delim("./data/Aperol_pilot_01_03_novice_B_cam1.txt", dec=",", sep="\t", header=T)
### select relevant columns
speaking.data.01.03 <- speaking.data.01.03 %>% select(
Code,
Anfang,
Ende,
Fläche,
Abdeckungsgrad..)
### filter only speaking time of teacher as row
speaking.data.01.03 <- speaking.data.01.03 %>% filter (Code == "speaking time\\teachter")
speaking.data.01.03 <- sum(speaking.data.01.03$Abdeckungsgrad..)
# read in data for 01_04_novice_C
speaking.data.01.04 <- read.delim("./data/Aperol_pilot_01_04_novice_C_cam1.txt", dec=",", sep="\t", header=T)
### select relevant columns
speaking.data.01.04 <- speaking.data.01.04 %>% select(
Code,
Anfang,
Ende,
Fläche,
Abdeckungsgrad..)
### filter only speaking time of teacher as row
speaking.data.01.04 <- speaking.data.01.04 %>% filter (Code == "speaking time\\teachter")
speaking.data.01.04 <- sum(speaking.data.01.04$Abdeckungsgrad..)
# read in data for 02_01_novice_A
speaking.data.02.01 <- read.delim("./data/Aperol_pilot_02_01_novice_A_glasses.txt", dec=",", sep="\t", header=T)
### select relevant columns
speaking.data.02.01 <- speaking.data.02.01 %>% select(
Code,
Anfang,
Ende,
Fläche,
Abdeckungsgrad..)
### filter only speaking time of teacher as row
speaking.data.02.01 <- speaking.data.02.01 %>% filter (Code == "speaking time\\teacher")
speaking.data.02.01 <- sum(speaking.data.02.01$Abdeckungsgrad..)
# read in data for 02_02_novice_B
speaking.data.02.02 <- read.delim("./data/Aperol_pilot_02_02_novice_B_cam1_AL_MK.txt", dec=",", sep="\t", header=T)
### select relevant columns
speaking.data.02.02 <- speaking.data.02.02 %>% select(
Dokumentgruppe,
Code,
Anfang,
Ende,
Fläche,
Abdeckungsgrad..)
### filter only speaking time of teacher as row
speaking.data.02.02 <- speaking.data.02.02 %>% filter (Code == "speaking time\\teacher",
Dokumentgruppe == "kodiert von Anna")
speaking.data.02.02 <- sum(speaking.data.02.02$Abdeckungsgrad..)
# read in data for 02_03_novice_C
speaking.data.02.03 <- read.delim("./data/Aperol_pilot_02_03_novice_C_cam1_AL_MK.txt", dec=",", sep="\t", header=T)
### select relevant columns
speaking.data.02.03 <- speaking.data.02.03 %>% select(
Dokumentgruppe,
Code,
Anfang,
Ende,
Fläche,
Abdeckungsgrad..)
### filter only speaking time of teacher as row
speaking.data.02.03 <- speaking.data.02.03 %>% filter (Code == "speaking time\\teachter",
Dokumentgruppe == "02_03_kodiert von Anna")
speaking.data.02.03 <- sum(speaking.data.02.03$Abdeckungsgrad..)
# read in data for 02_04_novice_D
speaking.data.02.04 <- read.delim("./data/Aperol_pilot_02_04_novice_D_cam1.txt", dec=",", sep="\t", header=T)
### select relevant columns
speaking.data.02.04 <- speaking.data.02.04 %>% select(
Code,
Anfang,
Ende,
Fläche,
Abdeckungsgrad..)
### filter only speaking time of teacher as row
speaking.data.02.04 <- speaking.data.02.04 %>% filter (Code == "speaking time\\teachter")
speaking.data.02.04 <- sum(speaking.data.02.04$Abdeckungsgrad..)
# read in table with coded speaking time included
speaking.data <- read.delim("./data/plus_coded_speaking_time_questionnaire_data_0802.txt", dec=",", sep="\t", header=T)
# to compare both sessions filter only Identical items
speaking.data <- speaking.data  %>% filter(str_detect(scale,
paste(c("Duration of speaking time"),
collapse = '|')))
# value sometimes contained text before filtering, we have to convert the numbers to numeric
speaking.data <- speaking.data %>%  mutate(value = as.numeric(value))
speaking.plot <- speaking.data %>%
ggplot(aes(x='Duration of speaking time', y=value, fill=group)) +
geom_boxplot() +
geom_jitter(color="black", size=0.4, alpha=0.9) +
theme_light() +
theme(
legend.position="none",
plot.title = element_text(size=11),
axis.text.x = element_text(size = 8)) +
facet_grid(group~perspective) +
ggtitle("Boxplot with individual points for Duration of speaking time") +
xlab("")
speaking.plot
# prepare data (selected from questionnaire data)
et.raw.data<-read.table("./data/Aperol_pilot_glasses_raw_fixation_saccades_metrics.tsv", dec=",", sep="\t", header=T)
# converting integer to numeric
et.raw.data <- et.raw.data %>%  mutate(Duration_of_interval = as.numeric(Duration_of_interval),
Total_duration_of_whole_fixations = as.numeric(Total_duration_of_whole_fixations),
Number_of_whole_fixations = as.numeric(Number_of_whole_fixations),
Average_duration_of_whole_fixations = as.numeric(Average_duration_of_whole_fixations)
)
# calculate the GRI
# create a basic table (tibble) using tidyverse functions
et.raw.table <- et.raw.data %>%
group_by(Participant, Variable) %>%
summarise("Fixation Number" = Number_of_whole_fixations,
"Fixation Duration" = Total_duration_of_whole_fixations,
"M Duration Fixation" = Average_duration_of_whole_fixations,
"TOI" = Duration_of_interval,
"GRI" = Average_duration_of_whole_fixations / Number_of_whole_fixations)
# format and insert table in manuscript
apa_table(
et.raw.table,
caption = "Number and Duration (in msec) of Fixations",
# note = "Write Note here",
escape = TRUE, # if TRUE special Latex characters are escaped; if this is turned to F captions cannot be rendered. I don't know why...
placement = "h", # position of table in page:  exact location (h), at the top (t), bottom (b)
font_size = "scriptsize" # options are tiny, scriptsize, footnotesize, small, normalsize (default), large, Large, LARGE, huge, Huge
)
# prepare data (selected from questionnaire data)
et.calib.data<-read.table("./data/Aperol_pilot_glasses_raw_ALL_metrics_calib_without_AOI_snapshot.tsv", dec=",", sep="\t", header=T)
# converting integer to numeric
et.calib.data <- et.calib.data %>%  mutate(Duration_of_interval = as.numeric(Duration_of_interval),
Total_duration_of_whole_fixations = as.numeric(Total_duration_of_whole_fixations),
Number_of_whole_fixations = as.numeric(Number_of_whole_fixations),
Average_duration_of_whole_fixations = as.numeric(Average_duration_of_whole_fixations)
)
# select relevant rows
et.calib.data <- et.calib.data %>% filter(TOI == "Calibration phase")
# calculate the GRI
# create a basic table (tibble) using tidyverse functions
et.calib.table <- et.calib.data %>%
group_by(Participant, Variable1) %>%
summarise("Fixation Number" = Number_of_whole_fixations,
"Fixation Duration" = Total_duration_of_whole_fixations,
"M Duration Fixation" = Average_duration_of_whole_fixations,
"TOI" = Duration_of_interval,
"GRI" = Average_duration_of_whole_fixations / Number_of_whole_fixations)
# format and insert table in manuscript
apa_table(
et.calib.table,
caption = "Number and Duration (in msec) of Fixations during calibration",
# note = "Write Note here",
escape = TRUE, # if TRUE special Latex characters are escaped; if this is turned to F captions cannot be rendered. I don't know why...
placement = "h", # position of table in page:  exact location (h), at the top (t), bottom (b)
font_size = "scriptsize" # options are tiny, scriptsize, footnotesize, small, normalsize (default), large, Large, LARGE, huge, Huge
)
library(xfun)
library(xfun)
#install.packages("needs")
#1
library(needs)
needs(tidyverse,
lubridate,
viridis,
grid,
gridExtra,
cowplot,
readxl,
ARTofR)
library(xfun)
library(knitr)
library(xfun)
detach("package:knitr", unload = TRUE)
library(knitr)
library(rmarkdown)
authornote: |
The Ethics Advisory Board of Leipzig University has dealt with the research project and has come to the conclusion that there are no objections to the implementation of this research project. The Ethics Advisory Board points out that the scientific and ethical responsibilty for the implementation of the project remains with the project director.
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("rmarkdown")
library(xfun)
library(xfun)
install.packages("xfun")
library("papaja")
r_refs("r-references.bib")
library("papaja")
r_refs("r-references.bib")
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
#install.packages("needs")
#1
library(needs)
needs(tidyverse,
lubridate,
viridis,
grid,
gridExtra,
cowplot,
readxl,
ARTofR)
# prepare data (selected from questionnaire data)
demo.data <- read_excel ("./data/data_empschul_labor_lehrperson_2021-11-24.xlsx",
dec=",", sep="\t", header=T)
